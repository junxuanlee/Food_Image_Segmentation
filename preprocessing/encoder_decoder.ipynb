{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model based on https://arxiv.org/ftp/arxiv/papers/1906/1906.02990.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================\n",
    "#USE THIS WHEN USING GPU\n",
    "#============================\n",
    "#import tensorflow as tf\n",
    "#tf.keras.backend.clear_session()\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(gpus[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asserted\n"
     ]
    }
   ],
   "source": [
    "#============================\n",
    "#USE THIS WHEN USING CPU\n",
    "#============================\n",
    "\n",
    "import tensorflow as tf\n",
    "try:\n",
    "    # Disable all GPUS\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        assert device.device_type != 'GPU'\n",
    "        print('asserted')\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Input, ReLU, BatchNormalization, concatenate,ZeroPadding2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional Layer\n",
    "def conv(n,k,f,s, input_layer):\n",
    "    #x = ZeroPadding2D(name = 'pad_'+n[5:])(input_layer)\n",
    "    x = Conv2D(filters=f,kernel_size=k,strides=s,padding='same',name=n)(input_layer)\n",
    "    x = BatchNormalization(name = 'bn_'+n[5:])(x)\n",
    "    x = ReLU(name = 'relu_'+n[5:])(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transposed Convolution Layer / Deconvolution Layer\n",
    "def convt(n,k,f,s,input_layer):\n",
    "    #x = ZeroPadding2D(name = 'padt_'+n[5:])(input_layer)\n",
    "    x = Conv2DTranspose(filters=f, kernel_size=k, strides=s,padding='same',name=n)(input_layer)\n",
    "    x = BatchNormalization(name = 'bnt_'+n[5:])(x)\n",
    "    x = ReLU(name = 'relut_'+n[5:])(x) \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skipped (long) Connected Convolutional Layer\n",
    "def sconv(n,k,f,s,con1,con2):\n",
    "    x = concatenate([con1,con2])\n",
    "    x = conv(n,k,f,s,x)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(nf,np):\n",
    "\n",
    "    input_layer = Input([416,416,3])\n",
    "\n",
    "    #ENCODER\n",
    "    c1 = conv('conv_1',3,16,2,input_layer)\n",
    "    c2 = conv('conv_2',3,32,2,c1)\n",
    "    c3 = conv('conv_3',3,64,2,c2)\n",
    "    c4 = conv('conv_4',3,128,2,c3)\n",
    "    c5 = conv('conv_5',3,256,2,c4)\n",
    "    c6 = conv('conv_6',3,512,1,c5)\n",
    "\n",
    "    #DECODER FOR FOOD\n",
    "    dc1 = convt('convt_1',3,512,2,c6)\n",
    "    sc1 = sconv('sconv_1',3,512,1,dc1,c4)\n",
    "    dc2 = convt('convt_2',3,256,2,sc1)\n",
    "    sc2 = sconv('sconv_2',3,256,1,dc2,c3)\n",
    "    dc3 = convt('convt_3',3,128,2,sc2)\n",
    "    sc3 = sconv('sconv_3',3,128,1,dc3,c2)\n",
    "    dc4 = convt('convt_4',3,64,2,sc3)\n",
    "    sc4 = sconv('sconv_4',3,63,1,dc4,c1)\n",
    "    dc5 = convt('convt_5',3,32,2,sc4)\n",
    "    c7 = conv('conv_7',1,nf,1,dc5) #nf = number of food class\n",
    "\n",
    "    #DECODER FOR PLATE\n",
    "    dc6 = convt('convt_6',3,512,2,c6)\n",
    "    sc5 = sconv('sconv_5',3,512,1,dc6,c4)\n",
    "    dc7 = convt('convt_7',3,256,2,sc5)\n",
    "    sc6 = sconv('sconv_6',3,256,1,dc7,c3)\n",
    "    dc8 = convt('convt_8',3,128,2,sc6)\n",
    "    sc7 = sconv('sconv_7',3,128,1,dc8,c2)\n",
    "    dc9 = convt('convt_9',3,64,2,sc7)\n",
    "    sc8 = sconv('sconv_8',3,64,1,dc9,c1)\n",
    "    dc10 = convt('convt_10',3,32,2,sc8)\n",
    "    c8 = conv('conv_8',1,np,1,dc10) #np = number of food class\n",
    "\n",
    "    model = Model(input_layer,[c7,c8])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each number of classes + 1 background class\n",
    "num_food = 8\n",
    "num_plates = 6\n",
    "\n",
    "model = model1(num_food,num_plates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#Loads images in a 4D array\n",
    "def load_images(img_names, model_size):\n",
    "    imgs = []\n",
    "\n",
    "    for img_name in img_names:\n",
    "        img = Image.open(img_name)\n",
    "        img = img.resize(size=model_size)\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs = np.concatenate(imgs)\n",
    "\n",
    "    return imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = 'C:/Users/Admin/Desktop/jun/University/Year 4/GDP/work/code/notebooks/run/dataset/food1c/train/food_images/images/3.jpg'\n",
    "img = cv2.imread(pp)\n",
    "img = cv2.resize(img,(416,416))\n",
    "img = np.expand_dims(img,0)\n",
    "img = img/255\n",
    "\n",
    "pic = load_images(['C:/Users/Admin/Desktop/jun/University/Year 4/GDP/work/code/notebooks/run/dataset/food1c/train/food_images/images/3.jpg'],(416,416))\n",
    "pic = pic/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001DF83C439D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 416, 416, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
